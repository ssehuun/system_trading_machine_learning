{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch4. Algorithm Trading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predictor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-15f152c748f1>, line 108)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-15f152c748f1>\"\u001b[1;36m, line \u001b[1;32m108\u001b[0m\n\u001b[1;33m    print \"- Time Lags=%s\" % (time_lags)\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "\n",
    "import os,sys,datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import statsmodels.tsa.stattools as ts\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.qda import QDA\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "parentPath = os.path.abspath(\"..\")\n",
    "if parentPath not in sys.path:\n",
    "    sys.path.insert(0, parentPath)\n",
    "\n",
    "from common import *\n",
    "\n",
    "\n",
    "def make_dataset(df, time_lags=5):\n",
    "    df_lag = pd.DataFrame(index=df.index)\n",
    "    df_lag[\"Close\"] = df[\"Close\"]\n",
    "    df_lag[\"Volume\"] = df[\"Volume\"]\n",
    "\n",
    "    df_lag[\"Close_Lag%s\" % str(time_lags)] = df[\"Close\"].shift(time_lags)\n",
    "    df_lag[\"Close_Lag%s_Change\" % str(time_lags)] = df_lag[\"Close_Lag%s\" % str(time_lags)].pct_change()*100.0\n",
    "\n",
    "    df_lag[\"Volume_Lag%s\" % str(time_lags)] = df[\"Volume\"].shift(time_lags)\n",
    "    df_lag[\"Volume_Lag%s_Change\" % str(time_lags)] = df_lag[\"Volume_Lag%s\" % str(time_lags)].pct_change()*100.0\n",
    "\n",
    "    df_lag[\"Close_Direction\"] = np.sign(df_lag[\"Close_Lag%s_Change\" % str(time_lags)])\n",
    "    df_lag[\"Volume_Direction\"] = np.sign(df_lag[\"Volume_Lag%s_Change\" % str(time_lags)])\n",
    "\n",
    "    return df_lag.dropna(how='any')\n",
    "\n",
    "\n",
    "def split_dataset(df,input_column_array,output_column,spllit_ratio):\n",
    "    split_date = get_date_by_percent(df.index[0],df.index[df.shape[0]-1],spllit_ratio)\n",
    "\n",
    "    input_data = df[input_column_array]\n",
    "    output_data = df[output_column]\n",
    "\n",
    "    # Create training and test sets\n",
    "    X_train = input_data[input_data.index < split_date]\n",
    "    X_test = input_data[input_data.index >= split_date]\n",
    "    Y_train = output_data[output_data.index < split_date]\n",
    "    Y_test = output_data[output_data.index >= split_date]\n",
    "\n",
    "    return X_train,X_test,Y_train,Y_test\n",
    "\n",
    "\n",
    "def get_date_by_percent(start_date,end_date,percent):\n",
    "    days = (end_date - start_date).days\n",
    "    target_days = np.trunc(days * percent)\n",
    "    target_date = start_date + datetime.timedelta(days=target_days)\n",
    "    #print days, target_days,target_date\n",
    "    return target_date\n",
    "\n",
    "\n",
    "def do_logistic_regression(x_train,y_train):\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    return classifier\n",
    "\n",
    "\n",
    "def do_random_forest(x_train,y_train):\n",
    "    classifier = RandomForestClassifier()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    return classifier\n",
    "\n",
    "\n",
    "def do_svm(x_train,y_train):\n",
    "    classifier = SVC()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    return classifier\n",
    "\n",
    "\n",
    "def test_predictor(classifier,x_test,y_test):\n",
    "    pred = classifier.predict(x_test)\n",
    "\n",
    "    hit_count = 0\n",
    "    total_count = len(y_test)\n",
    "    for index in range(total_count):\n",
    "        if (pred[index]) == (y_test[index]):\n",
    "            hit_count = hit_count + 1\n",
    "    \n",
    "    hit_ratio = hit_count/total_count\n",
    "    score = classifier.score(x_test, y_test)\n",
    "    #print \"hit_count=%s, total=%s, hit_ratio = %s\" % (hit_count,total_count,hit_ratio)\n",
    "\n",
    "    return hit_ratio, score\n",
    "    # Output the hit-rate and the confusion matrix for each model\n",
    "    \n",
    "    #print(\"%s\\n\" % confusion_matrix(pred, y_test))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Calculate and output the CADF test on the residuals\n",
    "\n",
    "    avg_hit_ratio = 0    \n",
    "    for time_lags in range(1,6):\n",
    "        print \"- Time Lags=%s\" % (time_lags)\n",
    "\n",
    "        for company in ['samsung','hanmi']:\n",
    "            df_company = load_stock_data('%s.data'%(company))\n",
    "\n",
    "            df_dataset = make_dataset(df_company,time_lags)\n",
    "            X_train,X_test,Y_train,Y_test = split_dataset(df_dataset,[\"Close_Lag%s\"%(time_lags),\"Volume_Lag%s\"%(time_lags)],\"Close_Direction\",0.75)\n",
    "            #print X_test\n",
    "\n",
    "            lr_classifier = do_logistic_regression(X_train,Y_train)\n",
    "            lr_hit_ratio, lr_score = test_predictor(lr_classifier,X_test,Y_test)\n",
    "\n",
    "            rf_classifier = do_random_forest(X_train,Y_train)\n",
    "            rf_hit_ratio, rf_score = test_predictor(rf_classifier,X_test,Y_test)\n",
    "\n",
    "            svm_classifier = do_svm(X_train,Y_train)\n",
    "            svm_hit_ratio, svm_score = test_predictor(rf_classifier,X_test,Y_test)\n",
    "\n",
    "            print \"%s : Hit Ratio - Logistic Regreesion=%0.2f, RandomForest=%0.2f, SVM=%0.2f\" % (company,lr_hit_ratio,rf_hit_ratio,svm_hit_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stationarity_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(diff)? (<ipython-input-3-7e84789a890e>, line 74)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-7e84789a890e>\"\u001b[1;36m, line \u001b[1;32m74\u001b[0m\n\u001b[1;33m    print diff\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(diff)?\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os,sys,datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import statsmodels.tsa.stattools as ts\n",
    "\n",
    "parentPath = os.path.abspath(\"..\")\n",
    "if parentPath not in sys.path:\n",
    "    sys.path.insert(0, parentPath)\n",
    "\n",
    "from common import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_hurst_exponent(df,lags_count=100):\n",
    "    lags = range(2, lags_count)\n",
    "    ts = np.log(df)\n",
    "\n",
    "    tau = [np.sqrt(np.std(np.subtract(ts[lag:], ts[:-lag]))) for lag in lags]\n",
    "    poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "\n",
    "    result = poly[0]*2.0\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_half_life(df):\n",
    "    price = pd.Series(df)  \n",
    "    lagged_price = price.shift(1).fillna(method=\"bfill\")  \n",
    "    delta = price - lagged_price  \n",
    "    beta = np.polyfit(lagged_price, delta, 1)[0] \n",
    "    half_life = (-1*np.log(2)/beta) \n",
    "\n",
    "    return half_life\n",
    "\n",
    "def random_walk(seed=1000, mu = 0.0, sigma = 1, length=1000):\n",
    "    \"\"\" this function creates a series of independent, identically distributed values\n",
    "    with the form of a random walk. Where the best prediction of the next value is the present\n",
    "    value plus some random variable with mean and variance finite \n",
    "    We distinguish two types of random walks: (1) random walk without drift (i.e., no constant\n",
    "    or intercept term) and (2) random walk with drift (i.e., a constant term is present).  \n",
    "    The random walk model is an example of what is known in the literature as a unit root process.\n",
    "    RWM without drift: Yt = YtÃ¢ÂÂ1 + ut\n",
    "    RWM with drift: Yt = ÃÂ´ + YtÃ¢ÂÂ1 + ut\n",
    "    \"\"\"\n",
    "    \n",
    "    ts = []\n",
    "    for i in range(length):\n",
    "        if i == 0:\n",
    "            ts.append(seed)\n",
    "        else:    \n",
    "            ts.append(mu + ts[i-1] + random.gauss(0, sigma))\n",
    "\n",
    "    return ts\n",
    "\n",
    "\n",
    "def draw_moving_average(df):\n",
    "    df.plot(style='k--')\n",
    "    pd.rolling_mean(df, 20).plot(style='k')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def do_mean_reversion(df,window_size,index):\n",
    "    df_ma = pd.rolling_mean(df,window_size)\n",
    "    df_std = pd.rolling_std(df,window_size)\n",
    "\n",
    "    diff = df.loc[index,0] - df_ma.loc[index,0]\n",
    "    print diff\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    start = datetime.datetime(2012, 1, 1)\n",
    "    end = datetime.datetime(2013, 1, 1)\n",
    "\n",
    "    arex = web.DataReader(\"AREX\", \"yahoo\", start, end)\n",
    "    wll = web.DataReader(\"WLL\", \"yahoo\", start, end)\n",
    "\n",
    "    df = pd.DataFrame(index=arex.index)\n",
    "    df[\"AREX\"] = arex[\"Adj Close\"]\n",
    "    df[\"WLL\"] = wll[\"Adj Close\"]\n",
    "\n",
    "    # Plot the two time series\n",
    "    plot_price_series(df, \"AREX\", \"WLL\")\n",
    "\n",
    "    # Display a scatter plot of the two time series\n",
    "    plot_scatter_series(df, \"AREX\", \"WLL\")\n",
    "\n",
    "    # Calculate optimal hedge ratio \"beta\"\n",
    "    res = ols(y=df['WLL'], x=df[\"AREX\"])\n",
    "    beta_hr = res.beta.x\n",
    "\n",
    "    # Calculate the residuals of the linear combination\n",
    "    df[\"res\"] = df[\"WLL\"] - beta_hr*df[\"AREX\"]\n",
    "\n",
    "    # Plot the residuals\n",
    "    plot_residuals(df)\n",
    "    \"\"\"\n",
    "    # Calculate and output the CADF test on the residuals\n",
    "    df_samsung = load_stock_data('samsung.data')\n",
    "    df_hanmi = load_stock_data('hanmi.data')\n",
    "    #adf_result = ts.adfuller(df_samsung[\"Close\"])\n",
    "    #pprint.pprint(adf_result)\n",
    "    \"\"\"\n",
    "    hurst_samsung = get_hurst_exponent(df_samsung['Close'])\n",
    "    hurst_hanmi = get_hurst_exponent(df_hanmi['Close'])\n",
    "    print \"Hurst Exponent : Samsung=%s, Hanmi=%s\" % (hurst_samsung,hurst_hanmi)\n",
    "\n",
    "    half_life_samsung = get_half_life(df_samsung['Close'])\n",
    "    half_life_hanmi = get_half_life(df_hanmi['Close'])\n",
    "    print \"Half_life : Samsung=%s, Hanmi=%s\" % (half_life_samsung,half_life_hanmi)\n",
    "    \"\"\"\n",
    "    #print df_samsung['Close']\n",
    "    #draw_moving_average(df_samsung['Close'])\n",
    "    do_mean_reversion(df_samsung['Close'],10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
